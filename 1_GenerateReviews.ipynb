{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to artificially generate reviews\n",
    "Note: took 3hrs on a GPU to generate 10k reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1695649635610,
     "user": {
      "displayName": "Joey Brown",
      "userId": "01530074625336929637"
     },
     "user_tz": -480
    },
    "id": "DxiNT3aqapYX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from textaugment import EDA\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import random\n",
    "import csv\n",
    "import tqdm\n",
    "DEBUG = False\n",
    "\n",
    "#Adapted from: https://github.com/Vamsi995/Paraphrase-Generator#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title  Price         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
       "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
       "\n",
       "                          profileName review/helpfulness  review/score  \\\n",
       "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
       "1                       Kevin Killian              10/10           5.0   \n",
       "2                        John Granger              10/11           5.0   \n",
       "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
       "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
       "\n",
       "   review/time                                   review/summary  \\\n",
       "0    940636800           Nice collection of Julie Strain images   \n",
       "1   1095724800                                Really Enjoyed It   \n",
       "2   1078790400  Essential for every personal and Public Library   \n",
       "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4   1107993600                           Good academic overview   \n",
       "\n",
       "                                         review/text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Books_rating.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:19<06:02,  3.81s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 100/100 [06:25<00:00,  3.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# print(len(df['Title'].unique()))\n",
    "#~212,404 books#\n",
    "unique_titles = df['Title'].unique()\n",
    "f = open('gen_text_review.csv', 'w', newline='')\n",
    "csvoutputfile = csv.writer(f)\n",
    "csvoutputfile.writerow(['Title','OriginalReview','GeneratedReview'])\n",
    "num_reviews_per_book  = 3\n",
    "\n",
    "eda_augment = EDA()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\") \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\").cuda()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for booktitle in tqdm.tqdm(unique_titles):\n",
    "    df_out = df[df[\"Title\"].str.lower().isin([booktitle.lower()])]\n",
    "    list_of_reviews = df_out['review/text'].sample(n = min(len(df_out),num_reviews_per_book)).to_list()\n",
    "\n",
    "    #If not enough reviews, use the same 1, augment with synonym swap\n",
    "    if len(list_of_reviews)<num_reviews_per_book:\n",
    "       text_to_augment = list_of_reviews[0]\n",
    "       syn_augmented = eda_augment.synonym_replacement(text_to_augment)\n",
    "       if DEBUG:\n",
    "        print(text_to_augment)\n",
    "        print(syn_augmented)\n",
    "    \n",
    "    #Shuffle sentences here as the paraphrasing method does not make very dissimilar texts\n",
    "    shuffled_list_of_reviews = []\n",
    "    for idx, r in enumerate(list_of_reviews):\n",
    "        sentences = sent_tokenize(r)\n",
    "        # if more than 5 sentences (very long review) randomly drop 1 sentence?\n",
    "        if len(sentences)>=5:\n",
    "            sentences.pop(random.randrange(len(sentences))) \n",
    "        shuffled_list_of_reviews.append(''.join([str(w) for w in random.sample(sentences, len(sentences))]))\n",
    "    \n",
    "    #Run inference on T5 (NLP model) to paraphrase the shuffled review#\n",
    "    for idx, r in enumerate(shuffled_list_of_reviews):\n",
    "       write_out_data = []\n",
    "       write_out_data.append(booktitle) #book title\n",
    "\n",
    "       text_input =  \"paraphrase: \" + r + \" </s>\"\n",
    "       encoding = tokenizer.encode_plus(text_input,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "       input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "       outputs = model.generate(\n",
    "           input_ids=input_ids, attention_mask=attention_masks,\n",
    "           max_length=256,\n",
    "           do_sample=True,\n",
    "           top_k=150,\n",
    "           top_p=0.95,\n",
    "           early_stopping=True,\n",
    "           num_return_sequences=1\n",
    "        )\n",
    "       for output in outputs:\n",
    "            line = tokenizer.decode(output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "            if DEBUG:\n",
    "                print(\"\\nOriginal:\",list_of_reviews[idx], \"\\nShuffled:\", r, \"\\nParaphrased:\", line)\n",
    "                print()\n",
    "            write_out_data.append(list_of_reviews[idx])\n",
    "            write_out_data.append(line)\n",
    "       csvoutputfile.writerow(write_out_data)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP8oq0GUc2SGXABnc1Y810+",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
